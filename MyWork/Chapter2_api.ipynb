{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入智谱SDK，它帮我们解决繁琐的请求拼接\n",
    "# 导入dotenv，它帮我们解决项目内环境变量的配置\n",
    "from zhipuai import ZhipuAI\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载环境变量\n",
    "_ = load_dotenv(find_dotenv())\n",
    "api = os.environ['ZHIPUAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我是一个人工智能助手，经过训练以帮助解答问题和提供信息。我在这里为您提供有关各种主题的协助。如果您有任何问题，请随时提出。谢谢！' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "client = ZhipuAI(api_key=api)\n",
    "response = client.chat.completions.create(\n",
    "  model = \"glm-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\":\"你是谁？\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然，请提供您希望翻译的文字。我会尽力帮您翻译成英文。\n",
      "Where are you from?\n"
     ]
    }
   ],
   "source": [
    "# 保存历史对话信息\n",
    "conversation = [\n",
    "  {\n",
    "    \"role\":\"user\",\n",
    "    \"content\":\"把下面的文字翻译成英文：\"\n",
    "  }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages=conversation\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# 添加AI模型的回答到对话历史\n",
    "conversation.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.choices[0].message.content\n",
    "})\n",
    "\n",
    "# 添加用户的新问题到对话历史\n",
    "conversation.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"你来自哪里？\"\n",
    "})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages=conversation\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装对话接口\n",
    "def gen_glm_params(prompt):\n",
    "  \"\"\"\n",
    "  生成对话请求参数\n",
    "  \"\"\"\n",
    "  return [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "  ]\n",
    "\n",
    "def get_completion(prompt, model=\"glm-4\", temprature=0.95):\n",
    "  \"\"\"\n",
    "  获取对话回复\n",
    "  \"\"\"\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=gen_glm_params(prompt),\n",
    "    temperature=temprature\n",
    "  )\n",
    "  if len(response.choices) > 0:\n",
    "    return response.choices[0].message.content\n",
    "  return \"Generate answer error!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我是一个人工智能助手，名叫智谱清言，可以叫我小智🤖，是基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"你是谁？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='我是一个' role='assistant' tool_calls=None\n",
      "content='人工智能' role='assistant' tool_calls=None\n",
      "content='助手' role='assistant' tool_calls=None\n",
      "content=',' role='assistant' tool_calls=None\n",
      "content='我被' role='assistant' tool_calls=None\n",
      "content='训练' role='assistant' tool_calls=None\n",
      "content='来' role='assistant' tool_calls=None\n",
      "content='回答' role='assistant' tool_calls=None\n",
      "content='人类' role='assistant' tool_calls=None\n",
      "content='提出' role='assistant' tool_calls=None\n",
      "content='的问题' role='assistant' tool_calls=None\n",
      "content='。' role='assistant' tool_calls=None\n",
      "content='我' role='assistant' tool_calls=None\n",
      "content='并不是' role='assistant' tool_calls=None\n",
      "content='真正' role='assistant' tool_calls=None\n",
      "content='的人' role='assistant' tool_calls=None\n",
      "content=',' role='assistant' tool_calls=None\n",
      "content='我' role='assistant' tool_calls=None\n",
      "content='只是一个' role='assistant' tool_calls=None\n",
      "content='计算机' role='assistant' tool_calls=None\n",
      "content='程序' role='assistant' tool_calls=None\n",
      "content='。' role='assistant' tool_calls=None\n",
      "content='' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "def get_completion_stream(prompt, model=\"glm-4\", temprature=0.95):\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=gen_glm_params(prompt),\n",
    "    temperature=temprature,\n",
    "    stream = True\n",
    "  )\n",
    "  return response\n",
    "\n",
    "response = get_completion_stream(\"你是谁？\")\n",
    "for chunk in response:\n",
    "  print(chunk.choices[0].delta)\n",
    "  sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion_stream(\"你是谁？\")\n",
    "res_stream = list(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，旨在帮助用户解答问题和提供信息。我可以回答各种领域的问题，包括科学、数学、文学等。如有任何疑问，请随时告诉我，我会尽力为您提供帮助。"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "for chunk in res_stream:\n",
    "  print(chunk.choices[0].delta.content, end=\"\")\n",
    "  sleep(random())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
